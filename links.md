## Papers to base this work on
[Primary]
- https://arxiv.org/abs/1909.04866 (Deep declarative networks) + [github](https://github.com/anucvml/ddn)
- https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf (Normalised cuts)

[Secondary, useful implementation]
- https://arxiv.org/abs/2007.14628 (Blind PnP net, from the DDN creators lab) + [github](https://github.com/dylan-campbell/bpnpnet)

## WIKIPEDIA PAGES - Covering relevant graph theory for normalised cuts
- https://en.wikipedia.org/wiki/Graph_partition
- https://en.wikipedia.org/wiki/Algebraic_connectivity
- https://en.wikipedia.org/wiki/Adjacency_matrix
- https://en.wikipedia.org/wiki/Degree_matrix
- https://en.wikipedia.org/wiki/Laplacian_matrix


- https://en.wikipedia.org/wiki/Segmentation-based_object_categorization

Eigen-decomposition stuff (useful for the Ncuts node and others?)
- https://arxiv.org/pdf/1507.00210.pdf (Deepmind paper, replacing batch normalisation)
- https://proceedings.neurips.cc/paper/2019/file/7dd0240cd412efde8bc165e864d3644f-Paper.pdf (PCA whitening)
- https://arxiv.org/pdf/1911.06491.pdf (from the stackoverflow question: https://stackoverflow.com/questions/58856160/why-do-tensorflow-and-pytorch-gradients-of-the-eigenvalue-decomposition-differ-f)
- https://arxiv.org/pdf/1903.11240.pdf (A number of eigenvalue/eigenvector problems, ones with trace may be useful for other applications?)

Useful for talking about Laplacian eigenvectors as a convex problem
- https://web.stanford.edu/~boyd/papers/pdf/cvx_opt_graph_lapl_eigs.pdf

Unsupervised image segmentation with soft Ncut loss
- https://arxiv.org/abs/1711.08506![image](https://user-images.githubusercontent.com/22828897/155698813-79d16b93-435f-4a30-98da-02b74d56b199.png)
