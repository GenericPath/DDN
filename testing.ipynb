{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Starting again, trying to solve it all...\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import scipy.optimize as opt\n",
    "# import numpy as np\n",
    "# import sys\n",
    "# sys.path.append(\"../\")\n",
    "# from ddn.pytorch.node import *\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "        \n",
    "# def objective(W, y):\n",
    "#     \"\"\"\n",
    "#     f(W,y) = y^T * (D-W) * y / y^T * D * y\n",
    "#     \"\"\"\n",
    "#     # W is an NxN symmetrical matrix with W(i,j) = w_ij\n",
    "#     D = W.sum(1).diag() # D is an NxN diagonal matrix with d on diagonal, for d(i) = sum_j(w(i,j))\n",
    "#     L = D - W\n",
    "    \n",
    "#     return torch.div(torch.mm(torch.mm(torch.t(y), L),y),torch.mm(torch.mm(torch.t(y),D),y))\n",
    "    \n",
    "# def equality_constraints(W, y):\n",
    "#     \"\"\"\n",
    "#     subject to y^T * D * 1 = 0\n",
    "#     \"\"\"\n",
    "#     # Ensure correct size and shape of y... scipy minimise flattens y         \n",
    "#     N = W.size(dim=0)\n",
    "    \n",
    "#     #x is an NxN symmetrical matrix with W(i,j) = w_ij\n",
    "#     D = W.sum(1).diag() # D is an NxN diagonal matrix with d on diagonal, for d(i) = sum_j(w(i,j))\n",
    "#     ONE = torch.ones(N,1)   # Nx1 vector of all ones\n",
    "    \n",
    "#     return torch.mm(torch.mm(torch.t(y),D), ONE)\n",
    "\n",
    "# def solve(W):\n",
    "#     \"\"\"\n",
    "#     Minimise the objective, by solving the second smallest eigenvector of laplacian\n",
    "#     (D-W)*y = lambda * D * y\n",
    "#     becomes D^-0.5 * (D-W) * D^-0.5 * y = lambda * y\n",
    "#     \"\"\"\n",
    "#     # normalised laplacian\n",
    "#     D = W.sum(1).diag()\n",
    "#     L = D - W\n",
    "#     # Solve using torch.linalg.eigh?\n",
    "#     eigval, eigvec = torch.linalg.eig(L)\n",
    "\n",
    "#     val = [np.round(i.real,4) for i in eigval]\n",
    "\n",
    "#     vec = []\n",
    "#     for i in range(len(eigvec)):\n",
    "#         v = [np.round(n.real,4) for n in eigvec[:,i]]\n",
    "#         vec.append(v)\n",
    "\n",
    "#     s = list(val).copy()\n",
    "#     s.sort()\n",
    "\n",
    "#     for i in range(len(eigval)):\n",
    "#         if val[i] == s[1]:\n",
    "#             second_smallest_eigval_vec = vec[i]\n",
    "#             break\n",
    "    \n",
    "#     return torch.tensor(second_smallest_eigval_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf1a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sample code automatically generated on 2022-03-07 03:07:10\n",
    "\n",
    "by www.matrixcalculus.org\n",
    "\n",
    "from input\n",
    "\n",
    "d/dy D.^-0.5*(D-W)*D.^-0.5*y = D.^(-0.5)*(D-W)*D.^(-0.5)\n",
    "\n",
    "where\n",
    "\n",
    "D is a matrix\n",
    "W is a matrix\n",
    "y is a vector\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import torch\n",
    "import autograd.numpy as np\n",
    "\n",
    "def fAndG(D, W, y):\n",
    "    assert isinstance(D, np.ndarray)\n",
    "    dim = D.shape\n",
    "    assert len(dim) == 2\n",
    "    D_rows = dim[0]\n",
    "    D_cols = dim[1]\n",
    "    assert isinstance(W, np.ndarray)\n",
    "    dim = W.shape\n",
    "    assert len(dim) == 2\n",
    "    W_rows = dim[0]\n",
    "    W_cols = dim[1]\n",
    "    assert isinstance(y, np.ndarray)\n",
    "    dim = y.shape\n",
    "    assert len(dim) == 1\n",
    "    y_rows = dim[0]\n",
    "    assert D_cols == W_cols == D_rows == W_rows\n",
    "    assert D_cols == y_rows == W_cols == D_rows == W_rows\n",
    "\n",
    "    T_0 = (D ** -0.5)\n",
    "    T_1 = (D - W)\n",
    "    functionValue = (T_0) @ ((T_1) @ ((T_0) @ (y)))\n",
    "    gradient = ((T_0) @ (T_1)) @ (T_0)\n",
    "\n",
    "    return functionValue, gradient\n",
    "\n",
    "def checkGradient(D, W, y):\n",
    "    # numerical gradient checking\n",
    "    # f(x + t * delta) - f(x - t * delta) / (2t)\n",
    "    # should be roughly equal to inner product <g, delta>\n",
    "    t = 1E-6\n",
    "    delta = np.random.randn(3)\n",
    "    f1, _ = fAndG(D, W, y + t * delta)\n",
    "    f2, _ = fAndG(D, W, y - t * delta)\n",
    "    f, g = fAndG(D, W, y)\n",
    "    print('approximation error',\n",
    "          np.linalg.norm((f1 - f2) / (2*t) - np.tensordot(g, delta, axes=1)))\n",
    "    \n",
    "\n",
    "def solve(W):\n",
    "    \"\"\"\n",
    "    Minimise the objective, by solving the second smallest eigenvector of laplacian\n",
    "    (D-W)*y = lambda * D * y\n",
    "    becomes D^-0.5 * (D-W) * D^-0.5 * y = lambda * y\n",
    "    \"\"\"\n",
    "    # laplacian\n",
    "    D = W.sum(1).diag()\n",
    "    L = D - W\n",
    "    # Solve using torch.linalg.eigh?\n",
    "    eigval, eigvec = np.linalg.eig(L)\n",
    "\n",
    "    val = [np.round(i.real,4) for i in eigval]\n",
    "\n",
    "    vec = []\n",
    "    for i in range(len(eigvec)):\n",
    "        v = [np.round(n.real,4) for n in eigvec[:,i]]\n",
    "        vec.append(v)\n",
    "\n",
    "    s = list(val).copy()\n",
    "    s.sort()\n",
    "\n",
    "    for i in range(len(eigval)):\n",
    "        if val[i] == s[1]:\n",
    "            second_smallest_eigval_vec = vec[i]\n",
    "            break\n",
    "\n",
    "    return second_smallest_eigval_vec\n",
    "\n",
    "def generateRandomData():\n",
    "    # D = np.random.rand(3, 3)\n",
    "    W = 5 * torch.tensor(np.random.rand(3, 3))\n",
    "    D = W.sum(1).diag()\n",
    "    y = solve(W)\n",
    "\n",
    "    return D.numpy(), W.numpy(), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230b46ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.18484682  0.          0.        ]\n",
      " [ 0.          7.6879524   0.        ]\n",
      " [ 0.          0.         10.20016319]]\n",
      "[[0.99548008 3.07876329 2.11060344]\n",
      " [3.99313814 0.99689913 2.69791514]\n",
      " [4.61491334 2.1901351  3.39511475]]\n",
      "[-0.3538 -0.0662  0.7005]\n",
      "functionValue =  [nan nan nan]\n",
      "gradient =  [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "numerical gradient checking ...\n",
      "approximation error nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/gwales/anaconda3/envs/ddn/lib/python3.7/site-packages/ipykernel_launcher.py:40: RuntimeWarning: divide by zero encountered in power\n",
      "/data/gwales/anaconda3/envs/ddn/lib/python3.7/site-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in matmul\n",
      "/data/gwales/anaconda3/envs/ddn/lib/python3.7/site-packages/ipykernel_launcher.py:43: RuntimeWarning: invalid value encountered in matmul\n"
     ]
    }
   ],
   "source": [
    "D, W, y = generateRandomData()\n",
    "\n",
    "print(D)\n",
    "print(W)\n",
    "print(y)\n",
    "\n",
    "\n",
    "value, grad = fAndG(D,W,y)\n",
    "\n",
    "functionValue, gradient = fAndG(D, W, y)\n",
    "print('functionValue = ', functionValue)\n",
    "print('gradient = ', gradient)\n",
    "\n",
    "print('numerical gradient checking ...')\n",
    "checkGradient(D, W, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a49186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddn",
   "language": "python",
   "name": "ddn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
