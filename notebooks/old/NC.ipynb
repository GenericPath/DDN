{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a555b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# or notebook for interactive?\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "from PIL import Image\n",
    "    \n",
    "# Weight matrix function\n",
    "def basic_weight(img, a, b):\n",
    "    \"\"\"\n",
    "    img = source image\n",
    "    a = coordinate 1 (x,y)\n",
    "    b = coordinate 2 (i,j)\n",
    "    \n",
    "    returns gaussian difference of (x,y) and (i,j)\n",
    "    \"\"\"\n",
    "    s_i = 1 # sigma variable for intensity\n",
    "    s_s = 6 # sigma variable for spatial\n",
    "    intensity = np.linalg.norm()\n",
    "    intensity = np.exp(-1 * intensity / s_i)\n",
    "    \n",
    "\n",
    "def create_weights(img):\n",
    "    \"\"\"\n",
    "    Convert the image into a weighted adjacency matrix (4 way, spatial + intensity weights)\n",
    "    based on the original 2000 paper\n",
    "    \"\"\"\n",
    "    x,y = img.size\n",
    "    N = x*y # number of verticies\n",
    "    \n",
    "    W = np.zeros((N,N)) # weights matrix (essentially a weighted adjacency graph)\n",
    "    \n",
    "#     connection = 4 # 4-way connected graph (so only calculate the 4 neighbours, instead of full graph)\n",
    "    \n",
    "    \n",
    "#     for i in range(x):\n",
    "#         for j in range(y):\n",
    "#             # i,j = the current pixel to compare other pixels against\n",
    "#             for i1 in range(-connection/2 + i, connection/2 + i):\n",
    "#                 for j2 in range(-connection/2 + j, connection/2 + j):\n",
    "#                     # i1,j2 = the neighbouring pixels\n",
    "#                     if (0 <= i1 < x) and (0 <= j1 < y):\n",
    "                        \n",
    "#                     else:\n",
    "#                         W[i1][j1] = 0\n",
    "                    \n",
    "    r = 1\n",
    "    s_i = 1\n",
    "    s_s = 6\n",
    "    counter = 0\n",
    "    for i1 in range(x):\n",
    "        for j1 in range(y):\n",
    "            list = []\n",
    "            for i2 in range(x):\n",
    "                for j2 in range(y):\n",
    "                    if ( (abs(i1-i2)+abs(j1-j2))< r  ): #1st norm\n",
    "                        intens = np.linalg.norm( [ img.getpixel((i1,j1)),img.getpixel((i2,j2)) ] , 2 )\n",
    "                        spat =  np.linalg.norm( [  (i1-i2), (j1-j2) ] , 2)\n",
    "                        intens = np.exp(-1*intens/s_i)\n",
    "                        spat = np.exp(-1*spat/s_s)\n",
    "                        w = intens*spat\n",
    "                    else:\n",
    "                        w=0\n",
    "                    list.append(w)\n",
    "            W[counter,:] = list\n",
    "            counter += 1\n",
    "\n",
    "    return W\n",
    "\n",
    "def segment_image(img, eigvec):\n",
    "    \"\"\"\n",
    "    Convert the eigenvector into a mask, to apply to the image to segment it\n",
    "    \"\"\"\n",
    "    x,y = img.size\n",
    "    print((x,y))\n",
    "    print(eigvec)\n",
    "    print(torch.sign(eigvec))\n",
    "    mask = torch.sign(eigvec)\n",
    "    for c,i in enumerate(eigvec):\n",
    "        prev = eigvec[c]\n",
    "        if (i>0.0001):\n",
    "            mask[c] = 0\n",
    "    mask2 = np.reshape( mask , (x,y) )\n",
    "    new_img = np.multiply( img ,mask2  ) # element wise mulitplication\n",
    "    return np.asarray(new_img)\n",
    "    \n",
    "    \n",
    "def solve(W):\n",
    "    \"\"\"\n",
    "    Calculate the second smallest eigenvector from the laplacian\n",
    "    \"\"\"\n",
    "    W = torch.from_numpy(np.asarray(W))\n",
    "    D = W.sum(0).diag() # D is an NxN diagonal matrix with d on diagonal, for d(i) = sum_j(w(i,j))\n",
    "    ONE = torch.ones(W.size(dim=0),1)   # Nx1 vector of all ones\n",
    "    L = D - W\n",
    "\n",
    "    val, vec = torch.linalg.eigh(L)\n",
    "    seen = {}\n",
    "    uniques = []\n",
    "    for (x,y) in zip(val, vec):\n",
    "        if x in seen:\n",
    "            continue\n",
    "        seen[x] = 1\n",
    "        uniques.append((x,y))\n",
    "    fiedler = sorted(uniques)[1][1]\n",
    "    return fiedler #, _ for the actual solve function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a3e4099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3503/2169752554.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mseg_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3503/3360652072.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mseen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0muniques\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mfiedler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfiedler\u001b[0m \u001b[0;31m#, _ for the actual solve function...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = Image.open('./data/clean.png').convert('L')\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "print(np.linalg.norm( [ image.getpixel((0,0)),image.getpixel((0,2)) ] , 2 ))\n",
    "\n",
    "\n",
    "seg_image = segment_image(image, solve(create_weights(image)))\n",
    "plt.imshow(seg_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
