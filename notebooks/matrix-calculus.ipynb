{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6792c9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functionValue =  1.3153852559735688\n",
      "gradient =  [ 0.45133761 -0.85020593 -1.26533441]\n",
      "numerical gradient checking ...\n",
      "approximation error 9.77025127468778e-11\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sample code automatically generated on 2022-03-15 01:31:44\n",
    "\n",
    "by www.matrixcalculus.org\n",
    "\n",
    "from input\n",
    "\n",
    "d/dy (y'*(D-W)*y)/(y'*D*y) = 1/(y'*D*y)*(D-W)*y+1/(y'*D'*y)*(D-W)'*y-(1/(y'*D*y).^2*y'*(D-W)*y*D*y+1/(y'*D'*y).^2*y'*(D-W)'*y*D'*y)\n",
    "\n",
    "where\n",
    "\n",
    "D is a matrix\n",
    "W is a matrix\n",
    "y is a vector\n",
    "\n",
    "The generated code is provided \"as is\" without warranty of any kind.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def fAndG(D, W, y):\n",
    "    assert isinstance(D, np.ndarray)\n",
    "    dim = D.shape\n",
    "    assert len(dim) == 2\n",
    "    D_rows = dim[0]\n",
    "    D_cols = dim[1]\n",
    "    assert isinstance(W, np.ndarray)\n",
    "    dim = W.shape\n",
    "    assert len(dim) == 2\n",
    "    W_rows = dim[0]\n",
    "    W_cols = dim[1]\n",
    "    assert isinstance(y, np.ndarray)\n",
    "    dim = y.shape\n",
    "    assert len(dim) == 1\n",
    "    y_rows = dim[0]\n",
    "    assert y_rows == W_rows == D_cols == D_rows == W_cols\n",
    "\n",
    "    t_0 = (D).dot(y)\n",
    "    t_1 = (y).dot(t_0)\n",
    "    T_2 = (D - W)\n",
    "    t_3 = (T_2).dot(y)\n",
    "    t_4 = (y).dot(t_3)\n",
    "    t_5 = (D.T).dot(y)\n",
    "    t_6 = (y).dot(t_5)\n",
    "    t_7 = (T_2.T).dot(y)\n",
    "    functionValue = (t_4 / t_1)\n",
    "    gradient = ((((1 / t_1) * t_3) + ((1 / t_6) * t_7)) - ((((1 / (t_1 ** 2)) * t_4) * t_0) + ((1 / (t_6 ** 2)) * ((y).dot(t_7) * t_5))))\n",
    "\n",
    "    return functionValue, gradient\n",
    "\n",
    "def checkGradient(D, W, y):\n",
    "    # numerical gradient checking\n",
    "    # f(x + t * delta) - f(x - t * delta) / (2t)\n",
    "    # should be roughly equal to inner product <g, delta>\n",
    "    t = 1E-6\n",
    "    delta = np.random.randn(3)\n",
    "    f1, _ = fAndG(D, W, y + t * delta)\n",
    "    f2, _ = fAndG(D, W, y - t * delta)\n",
    "    f, g = fAndG(D, W, y)\n",
    "    print('approximation error',\n",
    "          np.linalg.norm((f1 - f2) / (2*t) - np.tensordot(g, delta, axes=1)))\n",
    "\n",
    "def generateRandomData():\n",
    "    D = np.random.randn(3, 3)\n",
    "    W = np.random.randn(3, 3)\n",
    "    y = np.random.randn(3)\n",
    "\n",
    "    return D, W, y\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    D, W, y = generateRandomData()\n",
    "    functionValue, gradient = fAndG(D, W, y)\n",
    "    print('functionValue = ', functionValue)\n",
    "    print('gradient = ', gradient)\n",
    "\n",
    "    print('numerical gradient checking ...')\n",
    "    checkGradient(D, W, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddn",
   "language": "python",
   "name": "ddn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
