{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal\n",
    "- Find the smallest eigenvector $\\lambda$ for the NC node\n",
    "\n",
    "Problem\n",
    "- Some methods too slow and/or crash on certain cases\n",
    "---\n",
    "Input\n",
    " - Positive definite matrix (symmetric)\n",
    "\n",
    "Output\n",
    " - Graph cut of the matrix (corresponds to the smallest eigenvector)\n",
    "---\n",
    "Must\n",
    "- Handle image sized inputs\n",
    "- Have reproducible results (fixed seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  0,   0,   0,  ...,   0, 254, 254],\n",
      "         [  0,   0,   0,  ...,   0, 254, 254],\n",
      "         [  0,   0,   0,  ...,   0, 254, 254],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 254, 254],\n",
      "         [254, 254, 254,  ..., 254,   0,   0],\n",
      "         [254, 254, 254,  ..., 254,   0,   0]]])\n",
      "(100,)\n",
      "torch.Size([1, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import torch\n",
    "## TODO: Begin with a simple 'image' that has a known cut, this way it can be tested if correct\n",
    "## May be able to compare to sklearn.cluster.SpectralClustering (https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html?highlight=lobpcg#r5f6cbeb1558e-4)\n",
    "\n",
    "seed = 123\n",
    "dtype = np.float64 # Currently doesn't do anything as random.rand doesn't accept\n",
    "n = 10\n",
    "# and possibly generate different sparisities?? As realistically will be somewhat sparse\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "# Random image of size\n",
    "# input = np.random.randint(0,255, n)\n",
    "\n",
    "# TODO: Test for larger sized (full correctly formed, symmetric pos def - but random, and fully random matricies)\n",
    "# pretend simple image\n",
    "input = np.array([1,1,1,1,255,255,255,255,255,255,\n",
    "                  1,1,1,1,255,255,255,255,255,255,\n",
    "                  1,1,1,1,255,255,255,255,255,255,\n",
    "                  1,1,1,1,255,255,255,255,255,255,\n",
    "                  1,1,1,1,255,255,255,255,255,255,\n",
    "                  1,1,1,1,255,255,255,255,255,255,\n",
    "                  1,1,1,1,1,255,255,255,255,255,\n",
    "                  1,1,1,1,1,255,255,255,255,255,\n",
    "                  1,1,1,1,1,1,255,255,255,255,\n",
    "                  1,1,1,1,1,1,1,1,255,255,])\n",
    "\n",
    "# in = n random numbers between 0 and 255 # probably better if its slightly realistic?\n",
    "A = linalg.fiedler(input)\n",
    "\n",
    "# TODO: Change this with a real image, and real values from it... \n",
    "#       but for now should be fine (same properties being symmetric positive semi-definite)\n",
    "\n",
    "A = A.reshape(1,n*n,n*n)\n",
    "A = torch.from_numpy(A)\n",
    "\n",
    "print(A)\n",
    "print(input.shape)\n",
    "print(A.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to https://gist.github.com/denis-bz/6a9d7379c8edf965b0a997c2ec2471e1\n",
    "\n",
    "# used to store each of the functions, and allow them to all take the single arg input\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "# scipy and numpy are used for the eigensolvers\n",
    "import scipy\n",
    "\n",
    "# TODO: reinstall scikit-sprase on mac to get it to install properly (wrong depecencies and unknown fix for mac)\n",
    "# until then just dont test unless on debian system\n",
    "# import sksparse \n",
    "\n",
    "\n",
    "# TODO: use the initial vector :)\n",
    "# TODO: and use it such that you test both v0 set to 0 and v0 set to random :) to see if any differences\n",
    "v0 = np.zeros_like(A) # initialise the initial vector to all zeros :)\n",
    "\n",
    "eigs_options = OrderedDict(\n",
    "    ## NOTE: Will need to set the v0 to something consistent\n",
    "    ## NOTE: and if neccessary any seeds used by them....\n",
    "    ## NOTE: All inputs will be positive definite so should be easy :)\n",
    "    \n",
    "    \n",
    "    # Types to try:\n",
    "    # - shift invert (as we are looking for smallest) (https://gist.github.com/denis-bz/2658f671cee9396ac15cfe07dcc6657d)\n",
    "    # - Power iteration, QR, LOBPCG\n",
    "    # - Lanzcos, Arnoldi\n",
    "    # - cholmod (https://scikit-sparse.readthedocs.io/en/latest/cholmod.html, https://stackoverflow.com/questions/59416098/finding-smallest-eigenvectors-of-large-sparse-matrix-over-100x-slower-in-scipy)\n",
    "    # - any gpu based ones? (pytorch perhaps?)\n",
    "    \n",
    "    # Options will include the driver for each as well as the unique methods\n",
    "    \n",
    "    \n",
    "    # The actual methods available\n",
    "    # scipy.linalg.eig \n",
    "    # scipy.linalg.eigh  # Should be good\n",
    "    # scipy.sparse.linalg.lobpcg\n",
    "    # scipy.sparse.linalg.eigs\n",
    "    # scipy.sparse.linalg.eigsh\n",
    "    # sksparse.cholmod.cholesky # Should be good\n",
    "    # scipy.sparse.linalg.bicg\n",
    "    # scipy.sparse.linalg.gmres\n",
    "    \n",
    "    # scipy.sparse.linalg.splu ??\n",
    "    # scipy.linalg.cholesky ??\n",
    "    # scipy.linalg.qr ??\n",
    "    \n",
    "    # numpy.linalg.cholesky\n",
    "    # numpy.linalg.qr\n",
    "    # numpy.linalg.eig\n",
    "    # numpy.linalg.eigh    # Should be good\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Each should just take one argument (A) the input matrix\n",
    "    \n",
    "    # Numpy (no params only inputs)\n",
    "    np_eig = np.linalg.eig,\n",
    "    np_eigh = np.linalg.eigh,\n",
    "    np_eigvals = np.linalg.eigvals,\n",
    "    \n",
    "    # Some parameters for scipy variants\n",
    "    sp_eig = partial(scipy.linalg.eig, check_finite=False), # No extra params\n",
    "    \n",
    "    \n",
    "    # TODO: think about the problem I am solving and figure which forms I should give....\n",
    "    # g is the generaized problem (where b is not None)\n",
    "    \n",
    "    # Subset by index only for evr, evx, and gvx\n",
    "    # driver sy for real\n",
    "    # syev is symmetric QR (slow but robust)\n",
    "    # syevr seen as optimal for most cases\n",
    "    # syevd is faster for more memeroy\n",
    "    # syevx could be useful for a single eigenvalue on large matricies...\n",
    "    sp_eigh = partial(scipy.linalg.eigh, check_finite=False, subset_by_index=[0,1]), # driver=, type=(generalized or not), \n",
    "    # defaults to driver=syevr...\n",
    "    \n",
    "    \n",
    "    \n",
    "    # NOTE: eigvalsh is a one-liner shorthand for scipy.linalg.eigh with the option eigvals_only=True \n",
    "    # so not useful for me as I only want eigenvectors :) \n",
    "    # np_eigvalsh = np.linalg.eigvalsh,  # _syevd\n",
    "    # sp_eigvalsh_ev = partial( scipy.linalg.eigvalsh, driver=\"ev\" ),  # ev evd evr evx\n",
    "    # sp_eigvalsh_evd = partial( scipy.linalg.eigvalsh, driver=\"evd\" ),\n",
    "    # sp_eigvalsh_evr = partial( scipy.linalg.eigvalsh, driver=\"evr\" ),\n",
    "\n",
    "    #    # evecs too --\n",
    "    # np_eigh = np.linalg.eigh,\n",
    "    # sp_eigh_evd = partial( scipy.linalg.eigh, driver=\"evd\" ),\n",
    "    # sp_eigh_evr = partial( scipy.linalg.eigh, driver=\"evr\" ),\n",
    "    #     # ev evd evr evx / gv gvd gvx generalized\n",
    "\n",
    "    #     # complex evals --\n",
    "    # np_eigvals = np.linalg.eigvals,  # _geev\n",
    "    # sp_eigvals = scipy.linalg.eigvals,\n",
    "\n",
    "    # np_lstsq = partial( np.linalg.lstsq, b=b, rcond=rcond ),\n",
    "    # sp_lstsq = partial( scipy.linalg.lstsq, b=b, cond=rcond ),\n",
    "\n",
    "    # np_solve = partial( np.linalg.solve, b=b ),\n",
    "    # sp_solve = partial( scipy.linalg.solve, b=b ),\n",
    "    # np_svd = partial( np.linalg.svd, compute_uv=False ),  # gesdd\n",
    "    # sp_svd = partial( scipy.linalg.svd, compute_uv=False ),  # lapack_driver : {'gesdd', 'gesvd'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_eig         :     0 sec  shape=torch.Size([1, 10, 10]) solution = 1.9968051118210863\n",
      "np_eigh        :     0 sec  shape=torch.Size([1, 10, 10]) solution = 1.0\n",
      "np_eigvals     :     0 sec  shape=torch.Size([1, 10, 10]) solution = 0.02197561675128176\n",
      "sp_eig         :     0 sec  shape=torch.Size([1, 10, 10]) solution = 1.9968051118210863\n",
      "sp_eigh        :     0 sec  shape=torch.Size([1, 10, 10]) solution = 1.0\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from nc import NormalizedCuts\n",
    "\n",
    "node = NormalizedCuts(eps=1e-8)#, bipart=args.bipart, symm_norm_L=args.symm_norm_L)\n",
    "\n",
    "for name, func in eigs_options.items():\n",
    "    t0 = time()\n",
    "    y,_ = node.solve(A,func=func) # The output also includes context (not needed herex)\n",
    "    t = time() - t0\n",
    "    \n",
    "    y = torch.real(y)\n",
    "    solution = node.objective(A.reshape(1,n*n,n*n),y.reshape(1,n,n))\n",
    "    # Check against objetive function, should solve as close to machine precision as possible    \n",
    "    print(f\"{name:15}: {t:5.0f} sec solution = {solution.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54d5fe071eb1c6cab15b1ad8a1b991a5b0fe2969ee0e1d70b33f4a0ef5774aa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
