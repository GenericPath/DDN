{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal\n",
    "- Find the smallest eigenvector $\\lambda$ for the NC node\n",
    "\n",
    "Problem\n",
    "- Some methods too slow and/or crash on certain cases\n",
    "---\n",
    "Input\n",
    " - Positive definite matrix (symmetric)\n",
    "\n",
    "Output\n",
    " - Graph cut of the matrix (corresponds to the smallest eigenvector)\n",
    "---\n",
    "Must\n",
    "- Handle image sized inputs\n",
    "- Have reproducible results (fixed seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  0,   0,   0,  ...,   0, 254, 254],\n",
      "         [  0,   0,   0,  ...,   0, 254, 254],\n",
      "         [  0,   0,   0,  ...,   0, 254, 254],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 254, 254],\n",
      "         [254, 254, 254,  ..., 254,   0,   0],\n",
      "         [254, 254, 254,  ..., 254,   0,   0]]])\n",
      "(100,)\n",
      "torch.Size([1, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import torch\n",
    "## TODO: Begin with a simple 'image' that has a known cut, this way it can be tested if correct\n",
    "## May be able to compare to sklearn.cluster.SpectralClustering (https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html?highlight=lobpcg#r5f6cbeb1558e-4)\n",
    "\n",
    "seed = 123\n",
    "dtype = np.float64 # Currently doesn't do anything as random.rand doesn't accept\n",
    "n = 10\n",
    "# and possibly generate different sparisities?? As realistically will be somewhat sparse\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "# Random image of size\n",
    "# input = np.random.randint(0,255, n)\n",
    "\n",
    "# pretend simple image\n",
    "input = np.array([1,1,1,1,255,255,255,255,255,255,\n",
    "                  1,1,1,1,255,255,255,255,255,255,\n",
    "                  1,1,1,1,255,255,255,255,255,255,\n",
    "                  1,1,1,1,255,255,255,255,255,255,\n",
    "                  1,1,1,1,255,255,255,255,255,255,\n",
    "                  1,1,1,1,255,255,255,255,255,255,\n",
    "                  1,1,1,1,1,255,255,255,255,255,\n",
    "                  1,1,1,1,1,255,255,255,255,255,\n",
    "                  1,1,1,1,1,1,255,255,255,255,\n",
    "                  1,1,1,1,1,1,1,1,255,255,])\n",
    "\n",
    "# in = n random numbers between 0 and 255 # probably better if its slightly realistic?\n",
    "A = linalg.fiedler(input)\n",
    "\n",
    "# TODO: Change this with a real image, and real values from it... \n",
    "#       but for now should be fine (same properties being symmetric positive semi-definite)\n",
    "\n",
    "A = A.reshape(1,n*n,n*n)\n",
    "A = torch.from_numpy(A)\n",
    "\n",
    "print(A)\n",
    "print(input.shape)\n",
    "print(A.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use something similar to iterate through each eigenvector\n",
    "```python\n",
    "raw = 'ABC'\n",
    "functions = [str.isalnum, str.isalpha, str.isdigit, str.islower,  str.isupper]\n",
    "\n",
    "for func in functions:\n",
    "    print(func(letter) for letter in raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to https://gist.github.com/denis-bz/6a9d7379c8edf965b0a997c2ec2471e1\n",
    "\n",
    "# used to store each of the functions, and allow them to all take the single arg input\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "# scipy and numpy are used for the eigensolvers\n",
    "import scipy\n",
    "\n",
    "# TODO: reinstall scikit-sprase on mac to get it to install properly (wrong depecencies and unknown fix for mac)\n",
    "# until then just dont test unless on debian system\n",
    "# import sksparse \n",
    "\n",
    "\n",
    "# TODO: use the initial vector :)\n",
    "# TODO: and use it such that you test both v0 set to 0 and v0 set to random :) to see if any differences\n",
    "v0 = np.zeros_like(A) # initialise the initial vector to all zeros :)\n",
    "\n",
    "eigs_options = OrderedDict(\n",
    "    ## NOTE: Will need to set the v0 to something consistent\n",
    "    ## NOTE: and if neccessary any seeds used by them....\n",
    "    ## NOTE: All inputs will be positive definite so should be easy :)\n",
    "    \n",
    "    \n",
    "    # Types to try:\n",
    "    # - shift invert (as we are looking for smallest) (https://gist.github.com/denis-bz/2658f671cee9396ac15cfe07dcc6657d)\n",
    "    # - Power iteration, QR, LOBPCG\n",
    "    # - Lanzcos, Arnoldi\n",
    "    # - cholmod (https://scikit-sparse.readthedocs.io/en/latest/cholmod.html, https://stackoverflow.com/questions/59416098/finding-smallest-eigenvectors-of-large-sparse-matrix-over-100x-slower-in-scipy)\n",
    "    # - any gpu based ones? (pytorch perhaps?)\n",
    "    \n",
    "    # Options will include the driver for each as well as the unique methods\n",
    "    \n",
    "    \n",
    "    # The actual methods available\n",
    "    # scipy.linalg.eig \n",
    "    # scipy.linalg.eigh  # Should be good\n",
    "    # scipy.sparse.linalg.lobpcg\n",
    "    # scipy.sparse.linalg.eigs\n",
    "    # scipy.sparse.linalg.eigsh\n",
    "    # sksparse.cholmod.cholesky # Should be good\n",
    "    # scipy.sparse.linalg.bicg\n",
    "    # scipy.sparse.linalg.gmres\n",
    "    \n",
    "    # scipy.sparse.linalg.splu ??\n",
    "    # scipy.linalg.cholesky ??\n",
    "    # scipy.linalg.qr ??\n",
    "    \n",
    "    # numpy.linalg.cholesky\n",
    "    # numpy.linalg.qr\n",
    "    # numpy.linalg.eig\n",
    "    # numpy.linalg.eigh    # Should be good\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Each should just take one argument (A) the input matrix\n",
    "    \n",
    "    # Numpy (no params only inputs)\n",
    "    np_eig = np.linalg.eig,\n",
    "    np_eigh = np.linalg.eigh,\n",
    "    np_eigvals = np.linalg.eigvals,\n",
    "    \n",
    "    # Some parameters for scipy variants\n",
    "    sp_eig = partial(scipy.linalg.eig, check_finite=False), # No extra params\n",
    "    \n",
    "    \n",
    "    # TODO: think about the problem I am solving and figure which forms I should give....\n",
    "    # g is the generaized problem (where b is not None)\n",
    "    \n",
    "    # Subset by index only for evr, evx, and gvx\n",
    "    # driver sy for real\n",
    "    # syev is symmetric QR (slow but robust)\n",
    "    # syevr seen as optimal for most cases\n",
    "    # syevd is faster for more memeroy\n",
    "    # syevx could be useful for a single eigenvalue on large matricies...\n",
    "    sp_eigh = partial(scipy.linalg.eigh, check_finite=False, subset_by_index=[0,0]), # driver=, type=(generalized or not), \n",
    "    # defaults to driver=syevr...\n",
    "    \n",
    "    \n",
    "    \n",
    "    # NOTE: eigvalsh is a one-liner shorthand for scipy.linalg.eigh with the option eigvals_only=True \n",
    "    # so not useful for me as I only want eigenvectors :) \n",
    "    # np_eigvalsh = np.linalg.eigvalsh,  # _syevd\n",
    "    # sp_eigvalsh_ev = partial( scipy.linalg.eigvalsh, driver=\"ev\" ),  # ev evd evr evx\n",
    "    # sp_eigvalsh_evd = partial( scipy.linalg.eigvalsh, driver=\"evd\" ),\n",
    "    # sp_eigvalsh_evr = partial( scipy.linalg.eigvalsh, driver=\"evr\" ),\n",
    "\n",
    "    #    # evecs too --\n",
    "    # np_eigh = np.linalg.eigh,\n",
    "    # sp_eigh_evd = partial( scipy.linalg.eigh, driver=\"evd\" ),\n",
    "    # sp_eigh_evr = partial( scipy.linalg.eigh, driver=\"evr\" ),\n",
    "    #     # ev evd evr evx / gv gvd gvx generalized\n",
    "\n",
    "    #     # complex evals --\n",
    "    # np_eigvals = np.linalg.eigvals,  # _geev\n",
    "    # sp_eigvals = scipy.linalg.eigvals,\n",
    "\n",
    "    # np_lstsq = partial( np.linalg.lstsq, b=b, rcond=rcond ),\n",
    "    # sp_lstsq = partial( scipy.linalg.lstsq, b=b, cond=rcond ),\n",
    "\n",
    "    # np_solve = partial( np.linalg.solve, b=b ),\n",
    "    # sp_solve = partial( scipy.linalg.solve, b=b ),\n",
    "    # np_svd = partial( np.linalg.svd, compute_uv=False ),  # gesdd\n",
    "    # sp_svd = partial( scipy.linalg.svd, compute_uv=False ),  # lapack_driver : {'gesdd', 'gesvd'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 100])\n",
      "np_eig\n",
      "np_eig         :     0 sec  shape=torch.Size([1, 10, 10]) solution = 1.0\n",
      "np_eigh\n",
      "np_eigh        :     0 sec  shape=torch.Size([1, 10, 10]) solution = 1.0\n",
      "np_eigvals\n",
      "np_eigvals     :     0 sec  shape=torch.Size([1, 10, 10]) solution = 0.02198015020649628\n",
      "sp_eig\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected square matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/garth/Desktop/DDN/notebooks/eigs-test.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/garth/Desktop/DDN/notebooks/eigs-test.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/garth/Desktop/DDN/notebooks/eigs-test.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m t0 \u001b[39m=\u001b[39m time()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/garth/Desktop/DDN/notebooks/eigs-test.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m y,_ \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49msolve(A,func\u001b[39m=\u001b[39;49mfunc) \u001b[39m# The output also includes context (not needed herex)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/garth/Desktop/DDN/notebooks/eigs-test.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m t \u001b[39m=\u001b[39m time() \u001b[39m-\u001b[39m t0\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/garth/Desktop/DDN/notebooks/eigs-test.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreal(y)\n",
      "File \u001b[0;32m~/Desktop/DDN/notebooks/../nc.py:290\u001b[0m, in \u001b[0;36mNormalizedCuts.solve\u001b[0;34m(self, A, func)\u001b[0m\n\u001b[1;32m    280\u001b[0m L_norm \u001b[39m=\u001b[39m L\n\u001b[1;32m    282\u001b[0m \u001b[39m# # # # # # # # # #\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39m# Solve eigenvectors and eigenvalues\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[39m# TODO: replace this bit\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m \n\u001b[1;32m    289\u001b[0m \u001b[39m# Solve\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m y \u001b[39m=\u001b[39m func(L_norm\u001b[39m.\u001b[39;49mcpu())\n\u001b[1;32m    291\u001b[0m \u001b[39m# Take solution out of eigenvalue, eigenvector pair (if needed)\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(y,\u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/ddn/lib/python3.8/site-packages/scipy/linalg/_decomp.py:213\u001b[0m, in \u001b[0;36meig\u001b[0;34m(a, b, left, right, overwrite_a, overwrite_b, check_finite, homogeneous_eigvals)\u001b[0m\n\u001b[1;32m    211\u001b[0m a1 \u001b[39m=\u001b[39m _asarray_validated(a, check_finite\u001b[39m=\u001b[39mcheck_finite)\n\u001b[1;32m    212\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(a1\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m a1\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m a1\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mexpected square matrix\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    214\u001b[0m overwrite_a \u001b[39m=\u001b[39m overwrite_a \u001b[39mor\u001b[39;00m (_datacopied(a1, a))\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m b \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: expected square matrix"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from nc import NormalizedCuts\n",
    "\n",
    "node = NormalizedCuts(eps=1e-8)#, bipart=args.bipart, symm_norm_L=args.symm_norm_L)\n",
    "\n",
    "print(A.shape)\n",
    "\n",
    "for name, func in eigs_options.items():\n",
    "    t0 = time()\n",
    "    y,_ = node.solve(A,func=func) # The output also includes context (not needed herex)\n",
    "    t = time() - t0\n",
    "    \n",
    "    y = torch.real(y)\n",
    "    solution = node.objective(A.reshape(1,n*n,n*n),y.reshape(1,n,n))\n",
    "    # Check against objetive function, should solve as close to machine precision as possible\n",
    "    # solution = node.objective(A, y=np.reshape(1,n)) # no idea if A makes sense here, but A should be a pretend W so D etc should still be correct..\n",
    "    \n",
    "    print(f\"{name:15}: {t:5.0f} sec  shape={y.shape} solution = {solution.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54d5fe071eb1c6cab15b1ad8a1b991a5b0fe2969ee0e1d70b33f4a0ef5774aa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
