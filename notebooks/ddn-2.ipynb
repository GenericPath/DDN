{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was an example of trying to use scipy to minimize, before realising it only works for scalar valued functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[-1.4901e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.4901e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.4901e-09,  0.0000e+00,  0.0000e+00]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The user-provided objective function must return a scalar value.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/data/gwales/anaconda3/envs/ddn/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22567/2425820365.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormalizedCuts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22567/2425820365.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m                               \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'eq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fun'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequality_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# constraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                               \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'BFGS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                               options={'disp': True}) #print output\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/gwales/anaconda3/envs/ddn/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[0;32m/data/gwales/anaconda3/envs/ddn/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0mgrad_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyfprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m     \u001b[0mgfk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/gwales/anaconda3/envs/ddn/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/gwales/anaconda3/envs/ddn/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mapprox_fprime\u001b[0;34m(xk, f, epsilon, *args)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \"\"\"\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/gwales/anaconda3/envs/ddn/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 raise ValueError(\"The user-provided \"\n\u001b[0m\u001b[1;32m    703\u001b[0m                                  \u001b[0;34m\"objective function must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                                  \"return a scalar value.\")\n",
      "\u001b[0;31mValueError\u001b[0m: The user-provided objective function must return a scalar value."
     ]
    }
   ],
   "source": [
    "# SCIPY SOLVE - doesn't work as it only works for SCALAR VALUED FUNCTIONS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.optimize as opt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from ddn.pytorch.node import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class NormalizedCuts(EqConstDeclarativeNode):\n",
    "    \"\"\"\n",
    "    A declarative node to embed Normalized Cuts into a Neural Network\n",
    "    \n",
    "    Normalized Cuts and Image Segmentation https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf\n",
    "    Shi, J., & Malik, J. (2000)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def objective(self, x, y):\n",
    "        \"\"\"\n",
    "        f(x,y) = y^T(D-W)y / y^TDy\n",
    "        for W = x\n",
    "        \"\"\"\n",
    "        # Ensure correct size and shape of y... scipy minimise flattens y         \n",
    "        N = x.size(dim=0)\n",
    "        y = torch.tensor(y).reshape(N,N)\n",
    "        \n",
    "        # x is an NxN symmetrical matrix with W(i,j) = w_ij\n",
    "        D = x.sum(1).diag() # D is an NxN diagonal matrix with d on diagonal, for d(i) = sum_j(w(i,j))\n",
    "        ONE = torch.ones(x.size(dim=0),1)   # Nx1 vector of all ones\n",
    "        L = D - x\n",
    "        \n",
    "        top_a = torch.mm(torch.t(y), L)\n",
    "        top_b = torch.mm(top_a, y)\n",
    "        \n",
    "        bot_a = torch.mm(torch.t(y), D)\n",
    "        bot_b = torch.mm(bot_a, y)\n",
    "        \n",
    "        \n",
    "        f = torch.div(top_b, bot_b)\n",
    "        print(f)\n",
    "        return f\n",
    "    \n",
    "    def equality_constraints(self, x, y):\n",
    "        \"\"\"\n",
    "        subject to y^TD1=0\n",
    "        \"\"\"\n",
    "        # Ensure correct size and shape of y... scipy minimise flattens y         \n",
    "        N = x.size(dim=0)\n",
    "        y = torch.tensor(y).reshape(N,N)\n",
    "        \n",
    "        #x is an NxN symmetrical matrix with W(i,j) = w_ij\n",
    "        D = x.sum(1).diag() # D is an NxN diagonal matrix with d on diagonal, for d(i) = sum_j(w(i,j))\n",
    "        ONE = torch.ones(N,1)   # Nx1 vector of all ones\n",
    "        \n",
    "        a = torch.mm(torch.t(y),D)\n",
    "        b = torch.mm(a,ONE)\n",
    "        return b\n",
    "\n",
    "    def solve(self, x):\n",
    "        N = x.size(dim=0)\n",
    "        x0 = torch.ones(N,N)\n",
    "        # requires scipy 1.4.1, otherwise you recieve strange errors and minimisation doesn't work\n",
    "        result = opt.minimize(lambda y: self.objective(x, y), # objective\n",
    "                              x0, # initial guess\n",
    "                              constraints={'type': 'eq', 'fun': lambda y: self.equality_constraints(x,y)}, # constraint\n",
    "                              method='BFGS',\n",
    "                              options={'disp': True}) #print output\n",
    "        \n",
    "        y = torch.tensor(result.x).reshape(N,N)\n",
    "        print(y)\n",
    "        return torch.tensor(result.x), None\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        instatiate parameter\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "    \n",
    "# GPU ID to use\n",
    "gpu = 1\n",
    "\n",
    "# Create model, set to use GPU\n",
    "model = Net()\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "node = NormalizedCuts()\n",
    "x = torch.tensor([[0,1,0], [2,0,3], [0,4,0]]).double()\n",
    "y,_ = node.solve(x)\n",
    "print(y)\n",
    "print(\"done\")\n",
    "# torch.cuda.set_device(gpu)\n",
    "# model = model.cuda(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor(2.)\n",
      "~~\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 5., 0.],\n",
      "        [0., 0., 4.]])\n",
      "tensor([[0., 1., 0.],\n",
      "        [2., 0., 3.],\n",
      "        [0., 4., 0.]])\n",
      "tensor([[ 3.,  0.,  0.],\n",
      "        [ 0., 10.,  0.],\n",
      "        [ 0.,  0.,  7.]])\n",
      "~~\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[10.],\n",
      "        [17.],\n",
      "        [15.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "W = torch.tensor([[0.,1.,0.], [2.,0.,3.], [0.,4.,0.]])\n",
    "\n",
    "print(A.size(dim=0))\n",
    "print(A[1,0])\n",
    "\n",
    "print(\"~~\")\n",
    "W = A   # W is an NxN symmetrical matrix with W(i,j) = w_ij\n",
    "D = W.sum(1).diag() # D is an NxN diagonal matrix with d on diagonal, for d(i) = sum_j(w(i,j))\n",
    "ONE = torch.ones(x.size(dim=0),1)   # Nx1 vector of all ones\n",
    "\n",
    "print(type(torch.t(W)))\n",
    "print(type(torch.mm(torch.t(W), D)))\n",
    "print(type(ONE))\n",
    "\n",
    "print(ONE)\n",
    "print(torch.t(W) * D * ONE)\n",
    "\n",
    "print(torch.mm(torch.mm(torch.t(W), D), ONE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was an attempt to move to pytorch.optim to solve the solution, however this\n",
    "- produced the incorrect solution (as you cannot supply constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, -0.5774, -0.2852, -0.7651])\n"
     ]
    }
   ],
   "source": [
    "# Pytorch optim solving\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.optimize as opt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from ddn.pytorch.node import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class NormalizedCuts(AbstractDeclarativeNode):\n",
    "    \"\"\"\n",
    "    A declarative node to embed Normalized Cuts into a Neural Network\n",
    "    \n",
    "    Normalized Cuts and Image Segmentation https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf\n",
    "    Shi, J., & Malik, J. (2000)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def objective(self, x, y):\n",
    "        \"\"\"\n",
    "        f(x,y) = y^T(D-W)y / y^TDy\n",
    "        for W = x\n",
    "        \"\"\"\n",
    "        W = x   # W is an NxN symmetrical matrix with W(i,j) = w_ij\n",
    "                \n",
    "        D = W.sum(1).diag() # D is an NxN diagonal matrix with d on diagonal, for d(i) = sum_j(w(i,j))\n",
    "        ONE = torch.ones(x.size(dim=0))   # Nx1 vector of all ones\n",
    "        L = D - W\n",
    "        \n",
    "        return (torch.mm(torch.mm((torch.t(y),L),y))/ (torch.mm(torch.transpose(y),D),y))\n",
    "    \n",
    "    def equality_constraints(self, x, y):\n",
    "        \"\"\"\n",
    "        subject to y^TD1=0\n",
    "        \"\"\"\n",
    "        W = x   # W is an NxN symmetrical matrix with W(i,j) = w_ij\n",
    "        D = W.sum(1).diag() # D is an NxN diagonal matrix with d on diagonal, for d(i) = sum_j(w(i,j))\n",
    "        ONE = torch.ones(x.size(dim=0))   # Nx1 vector of all ones\n",
    "        return torch.mm(torch.mm((torch.t(y),D),ONE))\n",
    "\n",
    "    def solve(self, x):\n",
    "        \n",
    "        \n",
    "        return y, None\n",
    "    \n",
    "    def _run_optimisation(self, *xs, y):\n",
    "        with torch.enable_grad():\n",
    "            opt = torch.optim.LBFGS([y],\n",
    "                                    lr=1.0,\n",
    "                                    max_iter=1000,\n",
    "                                    max_eval=None,\n",
    "                                    tolerance_grad=1e-40,\n",
    "                                    tolerance_change=1e-40,\n",
    "                                    history_size=100,\n",
    "                                    line_search_fn=\"strong_wolfe\"\n",
    "                                    )\n",
    "            def reevaluate():\n",
    "                opt.zero_grad()\n",
    "                f = self.objective(*xs, y=y).sum() # sum over batch elements\n",
    "                f.backward()\n",
    "                return f\n",
    "            opt.step(reevaluate)\n",
    "        return y\n",
    "\n",
    "node = NormalizedCuts()\n",
    "x = torch.tensor([[0,1,0], [2,0,3], [0,4,0]])\n",
    "y,_ = node.solve(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was an attempt to solve iteratively, using all tracked functions from autograd.numpy or pytorch\n",
    "\n",
    "The idea being it could track the iterative steps and still calculate the gradient (in hindsight not a great idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, -0.5774, -0.2852, -0.7651])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22567/3799347483.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_22567/3799347483.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# L_sym = torch.mm(torch.mm(torch.diag(torch.pow(torch.diag(D),-0.5)),L),torch.diag(torch.pow(torch.diag(D),-0.5)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: self must be a matrix"
     ]
    }
   ],
   "source": [
    "import autograd.numpy as np\n",
    "import torch\n",
    "from autograd import grad, jacobian\n",
    "\n",
    "def gradient(f, x, y):\n",
    "    fY = grad(f,1)\n",
    "    fYY = jacobian(fY, 1)\n",
    "    fXY = jacobian(fY, 0)\n",
    "    \n",
    "    return -1.0 * np.linalg.solve(fYY(x,y), fXY(x,y))\n",
    "\n",
    "\n",
    "x = torch.tensor([[0,1,0,0], [1,0,0,3], [0,0,0,0], [0,3,0,0]]).double()\n",
    "\n",
    "def objective(x, y):\n",
    "        # x is an NxN symmetrical matrix with W(i,j) = w_ij\n",
    "        D = x.sum(0).diag() # D is an NxN diagonal matrix with d on diagonal, for d(i) = sum_j(w(i,j))\n",
    "        ONE = torch.ones(x.size(dim=0),1)   # Nx1 vector of all ones\n",
    "        L = D - x\n",
    "        \n",
    "        # L_sym = torch.mm(torch.mm(torch.diag(torch.pow(torch.diag(D),-0.5)),L),torch.diag(torch.pow(torch.diag(D),-0.5)))\n",
    "        return torch.mm(torch.mm(torch.t(y),L), y)\n",
    "    \n",
    "def solve(x):\n",
    "        D = x.sum(0).diag() # D is an NxN diagonal matrix with d on diagonal, for d(i) = sum_j(w(i,j))\n",
    "        ONE = torch.ones(x.size(dim=0),1)   # Nx1 vector of all ones\n",
    "        L = D - x\n",
    "        \n",
    "        val, vec = torch.linalg.eigh(L)\n",
    "        seen = {}\n",
    "        uniques = []\n",
    "        for (x,y) in zip(val, vec):\n",
    "            if x in seen:\n",
    "                continue\n",
    "            seen[x] = 1\n",
    "            uniques.append((x,y))\n",
    "        fiedler = sorted(uniques)[1][1]\n",
    "        return fiedler, _\n",
    "    \n",
    "x = torch.tensor([[0,1,0,0], [1,0,0,3], [0,0,0,0], [0,3,0,0]]).double()\n",
    "y,_ = solve(x)\n",
    "type(y)\n",
    "print(y)\n",
    "gradient(objective(x,y),x ,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98854.2753754  104142.66221626  92460.67919163 109064.65407346\n",
      "  107222.1442791 ]\n",
      " [104142.66221626 141858.63181405 103985.84690384 157299.66602452\n",
      "  131495.35491065]\n",
      " [ 92460.67919163 103985.84690384 116752.6405859  139256.92311514\n",
      "   95619.87134508]\n",
      " [109064.65407346 157299.66602452 139256.92311514 206826.68273427\n",
      "  131264.5428598 ]\n",
      " [107222.1442791  131495.35491065  95619.87134508 131264.5428598\n",
      "  135106.71342282]]\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 4., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 3.]], dtype=torch.float64)\n",
      "tensor([[[1., 0., 0., 0.],\n",
      "         [0., 4., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 3.]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# This semi works, but the solution is wrong and the gradient crashes half way\n",
    "\n",
    "import autograd.numpy as np\n",
    "import torch\n",
    "from autograd import grad, jacobian\n",
    "\n",
    "def gradient(f, x, y):\n",
    "    fY = grad(f,1)\n",
    "    fYY = jacobian(fY, 1)\n",
    "    fXY = jacobian(fY, 0)\n",
    "    \n",
    "    return -1.0 * np.linalg.solve(fYY(x,y), fXY(x,y))\n",
    "\n",
    "n = 5\n",
    "M = np.random.uniform(0,255,(n,n))\n",
    "symm = M@M.T\n",
    "# test for symmetry\n",
    "print(symm)\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "x = torch.tensor(symm, requires_grad=True)\n",
    "\n",
    "D = x.sum(0).diag() # D is an NxN diagonal matrix with d on diagonal, for d(i) = sum_j(w(i,j))\n",
    "ONE = torch.ones(x.size(dim=0),1)   # Nx1 vector of all ones\n",
    "L = D - x\n",
    "\n",
    "# L.backward(x)\n",
    "\n",
    "L.t()\n",
    "\n",
    "\n",
    "x = torch.tensor([[0,1,0,0], [1,0,0,3], [0,0,0,0], [0,3,0,0]]).double()\n",
    "D = x.sum(0).diag()\n",
    "print(D)\n",
    "\n",
    "x1 = torch.tensor([[[0,1,0,0], [1,0,0,3], [0,0,0,0], [0,3,0,0]]]).double()\n",
    "D = torch.einsum('bij->bj', x1)\n",
    "d1, d2 = D.size()\n",
    "D = torch.diag_embed(D)\n",
    "print(D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
